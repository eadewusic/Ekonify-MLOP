<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ekonify - Waste Classification</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
</head>

<body>
    <header>
        <div>
            <a href="./home.html" class="logo">
                <i class="fa-solid fa-recycle"></i>
                <span>Ekonify</span>
            </a>
        </div>
        <nav>
            <ul>
                <li><a href="./predict.html">Predict</a></li>
                <li><a href="./retrain.html">Retrain</a></li>
                <li><a href="./visualization.html">Visualization</a></li>
            </ul>
        </nav>
    </header>

    <main class="visualize-container"> 
        <div class="stats-container">
            <div class="stat">
                <strong>75%</strong>
                <span>Model Accuracy</span>
            </div>
            <div class="stat">
                <strong>1,274,985</strong>
                <span>Total Predictions</span>
            </div>
            <div class="stat">
                <strong>567</strong>
                <span>Tons CO‚ÇÇ Saved</span>
            </div>
        </div>
    
        <div class="visualization-grid">
            <div class="visualization-card">
                <img src="/front-end/images/class-imbalance.png" alt="Class Distribution"
                    class="visualization-image" />
                <div class="visualization-content">
                    <h3 class="visualization-title"><strong>Class Distribution</strong></h3>
                    <p class="visualization-description">The bar chart illustrates the number of images across ten classes: plastic, cardboard, brown-glass, metal, paper, biological, green-glass, battery, trash, clothes, white-glass, and shoes, revealing a significant class imbalance, particularly the dominance of the "clothes" class.</p>
                    <ul class="key-points">
                        <li><strong>Dominant Class (Clothes):</strong> The "clothes" class has the most images, exceeding 5000, creating a substantial class imbalance that could introduce
                        bias in predictions.</li>
                        <li><strong>Underrepresented Classes:</strong> The classes "plastic," "brown-glass," "biological," "green-glass," and "white-glass" have the fewest images, each under
                        1000. This could lead to poor generalization and high misclassification rates for these classes.</li>
                        <li><strong>Solution - Oversampling:</strong> After oversampling, the dataset now has a balanced distribution with each class having 5325 images, improving the model's ability to generalize across all classes and reduce potential bias towards the previously dominant "clothes" class.</li>
                    </ul>
                </div>
            </div>

            <div class="visualization-card">
                <img src="/front-end/images/pixel-intensity.png" alt="Distribution" class="visualization-image" />
                <div class="visualization-content">
                    <h3 class="visualization-title"><strong>Pixel Intensity Distribution</strong></h3>
                    <p class="visualization-description">The pixel intensity distribution graph provides a detailed visualization of
                        the frequency of pixel values across the
                        dataset images, which is essential for understanding image characteristics and informing preprocessing
                        decisions.</p>
                    <ul class="key-points">
                        <li><strong>Balanced Mid-Range Distribution:</strong> The distribution shows a concentration of pixel values
                            in the mid-range (100-150), with prominent peaks around 110-120, indicating good contrast in the
                            majority of the images.</li>
                        <li><strong>Multi-Modal Pattern:</strong> The presence of distinct peaks (around 110-120 and 180-190)
                            suggests different brightness regions within the images,
                            which is typical in images with well-defined features or structures.</li>
                        <li><strong>Good Dynamic Range:</strong> The distribution spans across most of the 0-255 range with minimal
                            values at the extremes, indicating images with good
                            dynamic range that aren't dominated by very dark or very bright pixels.</li>
                        <li><strong>Solution - Preprocessing:</strong> While this distribution is already well-balanced, further enhancements could include subtle histogram equalization or
                        normalization to 0-1 range to optimize neural network performance.</li>
                    </ul>
                </div>
            </div>
    
            <div class="visualization-card">
                <img src="/front-end/images/retrained-graph.png" alt="Training & Validation Performance"
                    class="visualization-image" />
                <div class="visualization-content">
                    <h3 class="visualization-title"><strong>Training & Validation Performance</strong></h3>
                    <p class="visualization-description">The left graph shows the trends in training and validation loss, while the right graph shows the corresponding trends in training and validation accuracy which are crucial for understanding the model's learning progress and its ability to generalize to unseen data.</p>
                    <ul class="key-points">
                        <li><strong>Successful Training:</strong> The model trained successfully, as shown from the decreasing loss and increasing accuracy on both the training and validation sets.</li>
                        <li><strong>Good Generalization:</strong> The convergence of the training and validation curves indicates good generalization, meaning the model is likely to perform well on new, unseen data.</li>
                        <li><strong>Potential for Improvement:</strong> While the model shows good performance, there might still be room for improvement, such as optimizing hyperparameters or
                        using more advanced architectures, to further increase accuracy and reduce loss.</li>
                    </ul>
                </div>
            </div>
    
            <div class="visualization-card">
                <img src="/front-end/images/image-dimension.png" alt="Distribution" class="visualization-image" />
                <div class="visualization-content">
                    <h3 class="visualization-title"><strong>Image Dimension Analysis</strong></h3>
                    <p class="visualization-description">The image dimension visualizations provide critical information about the dataset's structural uniformity, which is
                    essential for model architecture design and preprocessing decisions.</p>
                    <ul class="key-points">
                        <li><strong>Consistent Image Dimensions:</strong> All images in the dataset have identical dimensions of 512 √ó 384 pixels, as demonstrated by the single-value spikes in
                        both the width and height histograms and the solitary point in the scatter plot.</li>
                        <li><strong>Standardized Aspect Ratio:</strong> The uniform dimensions indicate a consistent aspect ratio of 4:3 (or 1.33:1), which eliminates the need for aspect ratio
                        adjustments during preprocessing.</li>
                        <li><strong>Preprocessing Advantage:</strong> This dimensional consistency eliminates the need for resizing operations in the preprocessing pipeline, preventing
                        potential distortions or information loss typically associated with variable-sized inputs.</li>
                        <li><strong>Model Optimization Opportunity:</strong> The fixed input size allows for precise model architecture design, enabling optimization of filter sizes and network
                        structure specifically for this 512 √ó 384 pixel format.</li>
                    </ul>
                </div>
            </div>
        </div>
    </main>

<!-- footer section -->

<footer>
    <div>
        <p>&copy; 2025 Ekonify. All rights reserved.</p>
        <p>made with ü§ç by <a href="https://linktr.ee/climiradi">Eunice <> Climiradi</a></p>
    </div>
</footer>
<script src="../config.js"></script>
<script src="/front-end/script.js"></script>
</body>

</html>
